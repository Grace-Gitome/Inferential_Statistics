{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance tests and Inference\n",
    "\n",
    "- Hypothesis testing\n",
    "- Analysis of variance\n",
    "- t-test\n",
    "- Z-test Anova\n",
    "- One way Anova\n",
    "- Two way Anova\n",
    "- Chi square test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "This is s statistical method used to make inferences or draw conclusion about a population based on a sample of data. It involves formulating a hypothesis about a population parameter and then collecting and analyzing data to determine whether the evidence supports or contradicts the hypothesis.\n",
    "\n",
    "### Terminologies used\n",
    "**Null Hypothesis (Ho)** - a statistical theory that suggests that no statistical significance exists between the populations (sample population versus whole population)\n",
    "\n",
    "**Alternative Hypothesis (Ha)** - it suggests there is a significant difference between the population parameters. Simply put, it is the contrast of the Null Hypothesis.<br>\n",
    "\n",
    "**Level of significance (α)** - It is a predefined threshold used in hypothesis testing to determine the critical region for making decisions about the null hypothesis.\n",
    "<br>\n",
    "The level of significance is chosen by the researcher before conducting the test and typically ranges from 0.01 to 0.10, with 0.05 being the most commonly used value. The significance level determines how strong the evidence must be against the null hypothesis in order to reject it.<br>\n",
    "\n",
    "Example:<br>\n",
    "If α =5%, that means we are okay to take a 5% risk and conclude there exists a difference when there is no actual difference.<br>\n",
    "\n",
    "**Critical value (C)** - A value in the distribution beyond which leads to the rejection of the Null Hypothesis. It is compared to the test statistic.<br>\n",
    "\n",
    "**Test Statistic (t)** - it is dependent on the test that we run. It is the decidig factor to reject or accept the Null Hypothesis. <br>\n",
    "\n",
    "*Types of Test Statistics:* <br>\n",
    "\n",
    "![Alt text](image-28.png)\n",
    "\n",
    "**P-value (p)** it is the propotion of samples (assuming the Null Hypothesis is true) that would be as extreme as the test statistic.<br>\n",
    "\n",
    "Example<br>\n",
    "Assume we are running a two-tailed Z-Test at 95% confidence. Then, the level of significance (α) = 5% = 0.05. Thus, we will have (1-α) = 0.95 proportion of data at the center, and α = 0.05 proportion will be equally shared to the two tails. Each tail will have (α/2) = 0.025 proportion of data. <br>\n",
    "The critical value i.e., Z95% or Zα/2 = 1.96 is calculated from the Z-scores table.<br>\n",
    "Take a look of a graphical illustration of the information above:\n",
    "\n",
    "![Alt text](image-29.png)\n",
    "\n",
    "### Steps of Hypothesis Testing\n",
    "1. Specify the Nully and Alternative Hypotheses about a population parameter.\n",
    "2. Set the Level of Significance(α)\n",
    "3. Collect Sample Data and calculate the Test Statistics and P-Value by running a Hypothesis test that well suits the data.\n",
    "4. Make a Conclusion: Reject or Accept the Null Hypothesis \n",
    "\n",
    "\n",
    "\n",
    "![Alt text](image-27.png)\n",
    "\n",
    "\n",
    "### Confusion Matrix in Hypothesis Testing\n",
    "\n",
    "![Alt text](image-30.png)\n",
    "\n",
    "**Confidence** - The probability of accepting a True Null Hypothesis. It is denoted as (1-α)<br>\n",
    "\n",
    "**Power of test** - The probability of rejecting a False Null Hypothesis i.e., the ability of the test to detect a difference. It is denoted as (1-β) and its value lies between 0 and 1.<br>\n",
    "The factors that affect the power of the test are sample size, population variability and the confidence.<br>\n",
    "\n",
    "**Type I error**: Occurs when we reject a True Null Hypothesis and is denoted as α.<br>\n",
    "\n",
    "**Type II error**: Occurs when we accept a False Null Hypothesis and is denoted as β.<br>\n",
    "\n",
    "**Accuracy** - Number of correct predictions / Total number of cases.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis tests distribution tree\n",
    "\n",
    "![Alt text](image-31.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Assume we are cylindrical pipe makers, we are interested in checking if the diameter of the pipe follows a Normal/Gaussian distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diameter (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diameter (cm)\n",
       "0          0.015\n",
       "1          0.020\n",
       "2          0.025\n",
       "3          1.025\n",
       "4          2.025"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Step1: Data Collection\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Datasets\\circle.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Step 2: Define H0 and Ha\n",
    "\n",
    "H0 = \"Data is normal\"\n",
    "Ha = \"Data is not normal\"\n",
    "\n",
    "#Set the significance level(α)= 5%\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded p-value: 0.95\n"
     ]
    }
   ],
   "source": [
    "##Step 3: Run a test to check the normality\n",
    "'''\n",
    "The shapiro test will be used in this case\n",
    "'''\n",
    "from scipy.stats import shapiro\n",
    "p_value = shapiro(df)[0]\n",
    "rounded_p_value = round(p_value, 2)\n",
    "\n",
    "\n",
    "print(\"Rounded p-value:\", rounded_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.95 <= 0.05. We reject the Null Hypothesis. Data is Normally Distributed\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Conclude using the p-value from step 3\n",
    "if p > alpha:\n",
    "    print(f\" {rounded_p_value} > {alpha}. We accept the Null Hypothesis. {H0}\")\n",
    "else:\n",
    "    print(f\" {rounded_p_value} <= {alpha}. We reject the Null Hypothesis. {H0}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Assuming the business has two production lines that make that produce the pipes. Check if there is any significant difference in the average diameter of pipes between the two production lines.<br>\n",
    "\n",
    "*Note:* <br>\n",
    "Diameter is continuous data and we are comparit data from two units. Therefore, <br>\n",
    "Y: Continuous<br>\n",
    "X: Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line 1</th>\n",
       "      <th>Line 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>1.415371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.138264</td>\n",
       "      <td>0.420645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647689</td>\n",
       "      <td>0.342715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.523030</td>\n",
       "      <td>0.802277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234153</td>\n",
       "      <td>0.161286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Line 1    Line 2\n",
       "0  0.496714  1.415371\n",
       "1  0.138264  0.420645\n",
       "2  0.647689  0.342715\n",
       "3  1.523030  0.802277\n",
       "4  0.234153  0.161286"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1: Generate dataset\n",
    "import numpy as np\n",
    "\n",
    "#Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "#Generate a sample dataset of 100 values from a normal distribution with a mean 0 and standard deviation of 1\n",
    "sample_data_line1 = np.abs(np.random.normal(loc= 0, scale=1, size = 100))\n",
    "sample_data_line2 = np.abs(np.random.normal(loc= 0, scale=1, size = 100))\n",
    "\n",
    "#Create a DataFrame using the generated sample data\n",
    "pipes = pd.DataFrame({'Line 1': sample_data_line1,\n",
    "                      'Line 2': sample_data_line2})\n",
    "\n",
    "#Display first 5 rows\n",
    "pipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2:Defining the H0 and Ha\n",
    "H0 = 'Data is Normally Distributed'\n",
    "Ha = 'Data is not Normally Distributed'\n",
    "\n",
    "#Set the significance level(α)= 5%\n",
    "alpha = 0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**<br>\n",
    "We have set the significance level (α) to 0.05, which means we are willing to accept a 5% chance of making a Type I error (rejecting the null hypothesis when it is true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapiro Test Results of 'Line 1' \n",
      "0.91 > 0.05. We accept Null Hypothesis. 'Line 1' Data is Normally Distributed\n",
      "\n",
      "Shapiro Test Results of 'Line 2' \n",
      "0.92 > 0.05. We accept Null Hypothesis. 'Line 2' Data is Normally Distributed\n"
     ]
    }
   ],
   "source": [
    "##Step 3: Run a test to check the normality\n",
    "'''\n",
    "Function to check normality using Shapiro-Wilk test\n",
    "'''\n",
    "\n",
    "# Function to check normality using Shapiro-Wilk test\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "def check_normality(data):\n",
    "\tfor columnName, columnData in pipes.items():\n",
    "\t\tprint('\\n' + \"Shapiro Test Results of '{}' \".format(columnName))\n",
    "\t\tp_value = round(shapiro(columnData.values)[0], 2)\n",
    "\n",
    "\t\tif p_value>alpha:\n",
    "\t\t\tprint(f\"{p_value} > {alpha}. We accept Null Hypothesis. '{columnName}' {H0}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{p_value} <= {alpha}. We reject Null Hypothesis. '{columnName}' {Ha}\")\n",
    "\n",
    "# Function call to check normality\n",
    "check_normality(pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variances Test Results' \n",
      "0.73 > 0.05. We accept the Null Hypothesis. Variances are equal or greater\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Check if variances are equal\n",
    "\n",
    "#Setting H0 and Ha\n",
    "H0 = 'Variances are equal or greater'\n",
    "Ha = 'Variances are not equal'\n",
    "\n",
    "from scipy.stats import levene\n",
    "def check_variances(dataset):\n",
    "\tprint('\\n' + \"Variances Test Results' \")\n",
    "\tp_value = round(levene(pipes['Line 1'], pipes['Line 2'])[1],2)\n",
    "\n",
    "\tif p_value>alpha:\n",
    "\t\tprint(f\"{p_value} > {alpha}. We accept the Null Hypothesis. {H0}\")\n",
    "\telse:\n",
    "\t\tprint(f\"{p_value} <= {alpha}. We reject Null Hypothesis. {Ha}\")\n",
    "\n",
    "check_variances(pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Sample T Test Results \n",
      "0.68 > 0.05. We accept the Null Hypothesis. There is no significant difference.\n"
     ]
    }
   ],
   "source": [
    "#Step 5: Run the T-test for the two samples with greater variances\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Defining Null and Alternative Hypotheses\n",
    "H0 = 'There is no significant difference.'\n",
    "Ha = 'There exist a significant difference.'\n",
    "\n",
    "#T-test function\n",
    "def t_test(df):\n",
    "    print('\\n' + \"2 Sample T Test Results \")\n",
    "    test_results = ttest_ind(pipes['Line 1'], pipes['Line 2'], equal_var=True)\n",
    "\n",
    "    p_value = round(test_results[1],2)\n",
    "\n",
    "    if p_value>alpha:\n",
    "        print(f\"{p_value} > {alpha}. We accept the Null Hypothesis. {H0}\")\n",
    "    else:\n",
    "        print(f\"{p_value} <= {alpha}. We reject Null Hypothesis. {Ha}\")\n",
    "\n",
    "t_test(pipes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Variance (ANOVA)\n",
    "\n",
    "This is a statistical test used to compare the means of three or more groups or populations. It determines if there are any significant differences between the group means and helps identify which groups are different from each other.\n",
    "\n",
    "![Alt text](image-32.png)\n",
    "\n",
    "### ANOVA Terminologies\n",
    "**Factor** - This is another term for the *independent variable* in your analysis. In a one-way ANOVA, there is one factor, while in a two-way ANOVA, there are two factors.\n",
    "\n",
    "**Levels** - These are the different groups or categories within a factor. For example, if the factor is ‘diet’ the levels might be ‘low fat’, ‘medium fat’, and ‘high fat’.\n",
    "\n",
    "**Response Variable** -  the *dependent variable* or the outcome that you are measuring.\n",
    "\n",
    "**Within-group Variance** - the variance or spread of scores within each level of your factor.\n",
    "\n",
    "**Between-group Variance** - the variance or spread of scores between the different levels of your factor.\n",
    "\n",
    "**Grand Mean** - the overall mean when you consider all the data together, regardless of the factor level.\n",
    "\n",
    "**Treatment Sums of Squares (SS)** - this represents the *between-group variability*. It is the sum of the squared differences between the group means and the grand mean.\n",
    "\n",
    "**Error Sums of Squares (SS)** -this represents the *within-group variability*. It’s the sum of the squared differences between each observation and its group mean.\n",
    "\n",
    "**Total Sums of Squares (SS)** -this is the sum of the Treatment SS and the Error SS. It represents the *total variability* in the data.\n",
    "\n",
    "**Degrees of Freedom (df)** - the number of values that have the freedom to vary when computing a statistic. <br>\n",
    "For example, if you have ‘n’ observations in one group, then the degrees of freedom for that group is ‘n-1’.\n",
    "\n",
    "**Mean Square (MS)**- the average squared deviation and is calculated by dividing the sum of squares by the corresponding degrees of freedom.\n",
    "\n",
    "**F-Ratio** - This is the test statistic for ANOVAs, and it’s the ratio of the between-group variance to the within-group variance.<br>\n",
    "If the between-group variance is significantly larger than the within-group variance, the F-ratio will be large and likely significant.\n",
    "\n",
    "**Null Hypothesis (H0)** - This is the hypothesis that there is no difference between the group means.\n",
    "\n",
    "**Alternative Hypothesis (H1)** - This is the hypothesis that there is a difference between at least two of the group means.\n",
    "\n",
    "**p-value** - the probability of obtaining a test statistic as extreme as the one that was actually observed, assuming that the null hypothesis is true.<br>\n",
    "If the p-value is less than the significance level (usually 0.05), then the null hypothesis is rejected in favor of the alternative hypothesis.\n",
    "\n",
    "**Post-hoc tests** -these are follow-up tests conducted after an ANOVA when the null hypothesis is rejected, to determine which specific groups’ means (levels) are different from each other. Examples include Tukey’s HSD, Scheffe, Bonferroni, among others.\n",
    "\n",
    "### Types of Analysis of Variance (ANOVA)\n",
    "\n",
    "- **One-way (or one-factor) ANOVA**\n",
    "\n",
    "This is the simplest type of ANOVA, which involves *one independent variable*. For example, comparing the effect of different types of diet (vegetarian, pescatarian, omnivore) on cholesterol level.\n",
    "\n",
    "- **Two-way (or two-factor) ANOVA**\n",
    "\n",
    "This involves* two independent variables*. This allows for testing the effect of each independent variable on the dependent variable, as well as testing if there’s an interaction effect between the independent variables on the dependent variable.\n",
    "\n",
    "- **Repeated Measures ANOVA**\n",
    "This is used when the same subjects are measured multiple times under different conditions, or at different points in time. This type of ANOVA is often used in longitudinal studies.\n",
    "\n",
    "- **Mixed Design ANOVA**\n",
    "This combines features of both between-subjects (independent groups) and within-subjects (repeated measures) designs. In this model, one factor is a between-subjects variable and the other is a within-subjects variable.\n",
    "\n",
    "- **Multivariate Analysis of Variance (MANOVA)**\n",
    "This is used when there are two or more dependent variables. It tests whether changes in the independent variable(s) correspond to changes in the dependent variables.\n",
    "\n",
    "- **Analysis of Covariance (ANCOVA)**\n",
    "This combines ANOVA and regression. ANCOVA tests whether certain factors have an effect on the outcome variable after removing the variance for which quantitative covariates (interval variables) account. This allows the comparison of one variable outcome between groups, while statistically controlling for the effect of other continuous variables that are not of primary interest.\n",
    "\n",
    "- **Nested ANOVA**\n",
    "This model is used when the groups can be clustered into categories. For example, if you were comparing students’ performance from different classrooms and different schools, “classroom” could be nested within “school.”\n",
    "\n",
    "### ANOVA formulas\n",
    "\n",
    "- #### Sum of Squares Total (SST)\n",
    "This represents the total variability in the data. It is the sum of the squared differences between each observation and the overall mean.\n",
    "\n",
    "![Alt text](image-33.png)\n",
    "\n",
    "Where:<br>\n",
    "*yi* - each individual data point<br>\n",
    "*y_mean* - the grand mean (mean of all observations)\n",
    "\n",
    "- ##### Sum of Squares Within (SSW)\n",
    "This represents the variability within each group or factor level. It is the sum of the squared differences between each observation and its group mean.\n",
    "\n",
    "![Alt text](image-34.png)\n",
    "\n",
    "Where:<br>\n",
    "*yij* - each individual data point within a group<br>\n",
    "*y_mean* - the mean of the ith group\n",
    "\n",
    "- #### Sum of Squares Between (SSB)\n",
    "This represents the variability between the groups. It is the sum of the squared differences between the group means and the grand mean, multiplied by the number of observations in each group.\n",
    "\n",
    "![Alt text](image-35.png)\n",
    "\n",
    "Where:<br>\n",
    "*ni* - the number of observations in each group<br>\n",
    "*y_mean* - the mean of the ith group<br>\n",
    "*y_mean* - the grand mean (mean of all observations)\n",
    "\n",
    "- #### Degrees of Freedom\n",
    "The degrees of freedom are the number of values that have the freedom to vary when calculating a statistic.<br><br>\n",
    "\n",
    "*For within groups (dfW)*\n",
    "\n",
    "![Alt text](image-36.png)\n",
    "\n",
    "*For between groups(dfB)*\n",
    "\n",
    "![Alt text](image-37.png)\n",
    "\n",
    "\n",
    "*For total(dfT)*\n",
    "\n",
    "![Alt text](image-38.png)\n",
    "\n",
    "<br>\n",
    "Where:<br>\n",
    "N represents the total number of observations<br>\n",
    "k represents the number of groups\n",
    "\n",
    "- #### Mean Squares\n",
    "Mean squares are the sum of squares divided by the respective degrees of freedom.\n",
    "\n",
    "\n",
    "*Mean Squares Between (MSB):* \n",
    "\n",
    "![Alt text](image-39.png)\n",
    "\n",
    "\n",
    "*Mean Squares Within (MSW):*\n",
    "\n",
    "![Alt text](image-40.png)\n",
    "\n",
    "- #### F-Statistic\n",
    "The F-statistic is used to test whether the variability between the groups is significantly greater than the variability within the groups.\n",
    "\n",
    "![Alt text](image-41.png)\n",
    "\n",
    "If the F-statistic is significantly higher than what would be expected by chance, we reject the null hypothesis that all group means are equal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use ANOVA\n",
    "ANOVA (Analysis of Variance) is used when you have three or more groups and you want to compare their means to see if they are significantly different from each other. It is a statistical method that is used in a variety of research scenarios.\n",
    "\n",
    "Different scenarios when one might use ANOVA:\n",
    "\n",
    "- #### Comparing Groups\n",
    "If you want to compare the performance of more than two groups, for example, testing the effectiveness of different teaching methods on student performance.\n",
    "\n",
    "- #### Evaluating Interactions\n",
    "In a two-way or factorial ANOVA, you can test for an interaction effect. This means you are not only interested in the effect of each individual factor, but also whether the effect of one factor depends on the level of another factor.\n",
    "\n",
    "- #### Repeated Measures\n",
    "If you have measured the same subjects under different conditions or at different time points, you can use repeated measures ANOVA to compare the means of these repeated measures while accounting for the correlation between measures from the same subject.\n",
    "\n",
    "- #### Experimental Designs\n",
    "ANOVA is often used in experimental research designs when subjects are randomly assigned to different conditions and the goal is to compare the means of the conditions.\n",
    "\n",
    "**Here are the assumptions that must be met to use ANOVA:**\n",
    "- **Normality**: The data should be approximately normally distributed.\n",
    "- **Homogeneity of Variances**: The variances of the groups you are comparing should be roughly equal. This assumption can be tested using Levene’s test or Bartlett’s test.\n",
    "- **Independence**: The observations should be independent of each other. This assumption is met if the data is collected appropriately with no related groups (e.g., twins, matched pairs, repeated measures)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of ANOVA\n",
    "\n",
    "- #### Comparing Multiple Groups\n",
    "One of the key advantages of ANOVA is the ability to compare the means of three or more groups. This makes it more powerful and flexible than the t-test, which is limited to comparing only two groups.\n",
    "\n",
    "- #### Control of Type I Error\n",
    "When comparing multiple groups, the chances of making a Type I error (false positive) increases. One of the strengths of ANOVA is that it controls the Type I error rate across all comparisons. This is in contrast to performing multiple pairwise t-tests which can inflate the Type I error rate.\n",
    "\n",
    "- #### Testing Interactions\n",
    "In factorial ANOVA, you can test not only the main effect of each factor, but also the interaction effect between factors. This can provide valuable insights into how different factors or variables interact with each other.\n",
    "\n",
    "- #### Handling Continuous and Categorical Variables\n",
    "ANOVA can handle both continuous and categorical variables. The dependent variable is continuous and the independent variables are categorical.\n",
    "\n",
    "- #### Robustness\n",
    "ANOVA is considered robust to violations of normality assumption when group sizes are equal. This means that even if your data do not perfectly meet the normality assumption, you might still get valid results.\n",
    "\n",
    "- #### Provides Detailed Analysis\n",
    "ANOVA provides a detailed breakdown of variances and interactions between variables which can be useful in understanding the underlying factors affecting the outcome.\n",
    "\n",
    "- #### Capability to Handle Complex Experimental Designs\n",
    "Advanced types of ANOVA (like repeated measures ANOVA, MANOVA, etc.) can handle more complex experimental designs, including those where measurements are taken on the same subjects over time, or when you want to analyze multiple dependent variables at once."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of ANOVA\n",
    "- #### Assumptions\n",
    "ANOVA relies on several assumptions including normality (the data follows a normal distribution), independence (the observations are independent of each other), and homogeneity of variances (the variances of the groups are roughly equal). If these assumptions are violated, the results of the ANOVA may not be valid.\n",
    "\n",
    "- #### Sensitivity to Outliers\n",
    "ANOVA can be sensitive to outliers. A single extreme value in one group can affect the sum of squares and consequently influence the F-statistic and the overall result of the test.\n",
    "\n",
    "- #### Dichotomous Variables\n",
    "ANOVA is not suitable for dichotomous variables (variables that can take only two values, like yes/no or male/female). It is used to compare the means of groups for a continuous dependent variable.\n",
    "\n",
    "- #### Lack of Specificity\n",
    "Although ANOVA can tell you that there is a significant difference between groups, it doesn’t tell you which specific groups are significantly different from each other. You need to carry out further post-hoc tests (like Tukey’s HSD or Bonferroni) for these pairwise comparisons.\n",
    "\n",
    "- #### Complexity with Multiple Factors\n",
    "When dealing with multiple factors and interactions in factorial ANOVA, interpretation can become complex. The presence of interaction effects can make main effects difficult to interpret.\n",
    "\n",
    "- #### Requires Larger Sample Sizes\n",
    "To detect an effect of a certain size, ANOVA generally requires larger sample sizes than a t-test.\n",
    "\n",
    "- #### Equal Group Sizes\n",
    "While not always a strict requirement, ANOVA is most powerful and its assumptions are most likely to be met when groups are of equal or similar sizes.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example \n",
    "Consider a situation where there are three different fertilizer treatments (Treatment A, Treatment B, and Treatment C). We would like to compare the effectiveness of these treatements on the yeild of maize.<br>\n",
    "We have measured the maize yield for each treatment. Let us conduct an ANOVA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment A</th>\n",
       "      <th>Treatment B</th>\n",
       "      <th>Treatment C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Treatment A  Treatment B  Treatment C\n",
       "0           34           15           33\n",
       "1           28           25           35\n",
       "2           36           26           40\n",
       "3           45           21           40\n",
       "4           27           28           16"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Setting the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "#Generating sample dataset of size 100 with normal distribution\n",
    "sample_A = np.abs(np.random.normal(loc= 30, scale=10, size = 100))\n",
    "sample_B = np.abs(np.random.normal(loc= 30, scale=10, size = 100))\n",
    "sample_C = np.abs(np.random.normal(loc= 30, scale=10, size = 100))\n",
    "\n",
    "# Ensure the values are between 10 and 50\n",
    "sample_A = np.clip(sample_A, 10, 50)\n",
    "sample_B = np.clip(sample_B, 10, 50)\n",
    "sample_C = np.clip(sample_C, 10, 50)\n",
    "\n",
    "# Convert the dataset to integers\n",
    "sample_A = sample_A.astype(int)\n",
    "sample_B = sample_B.astype(int)\n",
    "sample_C = sample_C.astype(int)\n",
    "\n",
    "#Create a DataFrame using the generated sample data\n",
    "fertlizer = pd.DataFrame({'Treatment A': sample_A,\n",
    "                          'Treatment B': sample_B,\n",
    "                          'Treatment C': sample_C})\n",
    "\n",
    "#Print the dataset\n",
    "fertlizer.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation** <br>\n",
    "*np.random.normal* - generates a random dataset of size 100 with a normal distribution <br>\n",
    "*loc* - this parameter sets the mean of the distribution (30) <br>\n",
    "*scale* - this parameter sets the standard deviation (10) <br>\n",
    "*size* - parameter sets the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Results:\n",
      "F-value: 0.7166036863869475\n",
      "p-value: 0.48925071938017795\n",
      "There is no significant difference between the means of the treatments.\n"
     ]
    }
   ],
   "source": [
    "#Performing ANOVA\n",
    "fvalue, pvalue = stats.f_oneway(fertlizer['Treatment A'],\n",
    "                                fertlizer['Treatment B'],\n",
    "                                fertlizer['Treatment C'])\n",
    "\n",
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Print the ANOVA results\n",
    "print('ANOVA Results:')\n",
    "print('F-value:', fvalue)\n",
    "print('p-value:', pvalue)\n",
    "\n",
    "# Check if the p-value is less than the significance level\n",
    "if pvalue < alpha:\n",
    "    print('There is a significant difference between the means of the treatments.')\n",
    "else:\n",
    "    print('There is no significant difference between the means of the treatments.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation** <br>\n",
    "The *f_oneway* function from the *scipy.stats *module is used to perform the ANOVA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
